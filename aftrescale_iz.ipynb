{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.15.0\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import seaborn as sns\n",
    "except:\n",
    "    !pip install seaborn\n",
    "    import seaborn as sns\n",
    "try:\n",
    "    import pymc as pm # For MCMC\n",
    "except:\n",
    "    !pip install pymc\n",
    "    import pymc as pm\n",
    "try:\n",
    "    import arviz as az # For MCMC package\n",
    "except:\n",
    "    !pip install arviz\n",
    "    import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "try:\n",
    "    import corner\n",
    "except:\n",
    "    !pip install corner\n",
    "    import corner\n",
    "\n",
    "print(pm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfg(a,b):\n",
    "    file_path = 'datasets/Donor%d_CD%d_Genes.csv' %(a,b)\n",
    "    all_df = pd.read_csv(file_path)\n",
    "    file_path = 'datasets/mt_genes_metadata.csv'\n",
    "    dfmeta = pd.read_csv(file_path)\n",
    "    protein_coding_genes = dfmeta[dfmeta['gene_type'] == 'protein_coding']\n",
    "    protein_names = protein_coding_genes['gene_name'].tolist()\n",
    "    df2 = pd.DataFrame([all_df[i] for i in protein_names]).T\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normiz_2(df,s_n = 1000):\n",
    "    df1 = df\n",
    "    listfinal = [sum(df.iloc[i]) for i in range(len(df))]\n",
    "    for i in range(len(df)):\n",
    "        df1.iloc[i] = df1.iloc[i]/listfinal[i] * s_n\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_log(df_n):\n",
    "    df_final = normiz_2(df_n).T\n",
    "    gene_mean = [np.mean(df_final.iloc[i]) for i in range(13)]\n",
    "    gene_var = [np.var(df_final.iloc[i]) for i in range(13)]\n",
    "    log_gene_mean = np.log(gene_mean)\n",
    "    log_gene_var = np.log(gene_var)\n",
    "    return log_gene_mean, log_gene_var\n",
    "\n",
    "def log_gene_plot(df_n):\n",
    "    df_final = normiz_2(df_n).T\n",
    "    gene_mean = [np.mean(df_final.iloc[i]) for i in range(13)]\n",
    "    gene_var = [np.var(df_final.iloc[i]) for i in range(13)]\n",
    "    log_gene_mean = np.log(gene_mean)\n",
    "    log_gene_var = np.log(gene_var)\n",
    "    plt.scatter(log_gene_mean,log_gene_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(a,b):\n",
    "    x = g_log(normiz_2(dfg(a,b)))[0]\n",
    "    y = g_log(normiz_2(dfg(a,b)))[1]\n",
    "\n",
    "    X = np.vstack([np.ones(len(x)), x]).T\n",
    "    # theta = (X^T X)^(-1) X^T y\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    a, b = theta\n",
    "    print(f\"Estimated parameters: a = {a}, b = {b}\")\n",
    "\n",
    "    y_pred = a + b * x\n",
    "\n",
    "    ss_total = np.sum((y - np.mean(y))**2)\n",
    "    ss_residual = np.sum((y - y_pred)**2)\n",
    "    r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "    print(f\"R-squared (R^2) value: {r_squared}\")\n",
    "\n",
    "    plt.scatter(x, y, label='Observed data')\n",
    "    plt.plot(x, y_pred, color='red', label='Fitted line')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Least Squares Estimation')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import nbinom, chisquare\n",
    "def negative_binomial_gof(data, bins=None):\n",
    "    \"\"\"\n",
    "    Perform a goodness-of-fit test to check if the data follows a negative binomial distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the observed data to test\n",
    "    - bins: int or None, number of bins to group the data into for stabilization\n",
    "    \n",
    "    Returns:\n",
    "    - chi_square_stat: float, the chi-square statistic\n",
    "    - p_value: float, the p-value of the chi-square test\n",
    "    - r: float, estimated parameter r (number of successes)\n",
    "    - p: float, estimated parameter p (probability of success)\n",
    "    \"\"\"\n",
    "    # Ensure data is a numpy array\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Step 1: Calculate mean and variance of the data\n",
    "    mean = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    \n",
    "    # Step 2: Estimate the parameters r and p\n",
    "    if variance <= mean:\n",
    "        raise ValueError(\"Variance must be greater than the mean for a negative binomial distribution.\")\n",
    "    \n",
    "    r = mean**2 / (variance - mean)\n",
    "    p = mean / variance\n",
    "    print(f\"Estimated parameters: r = {r}, p = {p}\")\n",
    "    \n",
    "    # Step 3: Create observed frequency table\n",
    "    if bins is None:\n",
    "        observed_freq = pd.Series(data).value_counts().sort_index()\n",
    "    else:\n",
    "        observed_freq, bin_edges = np.histogram(data, bins=bins)\n",
    "        observed_freq = pd.Series(observed_freq, index=bin_edges[:-1])\n",
    "    \n",
    "    # Step 4: Calculate expected frequencies\n",
    "    expected_freq = []\n",
    "    for k in observed_freq.index:\n",
    "        prob = nbinom.pmf(k, r, p)\n",
    "        expected_freq.append(prob * len(data))\n",
    "    \n",
    "    # Convert to numpy arrays for the chi-square test\n",
    "    observed_freq = observed_freq.values\n",
    "    expected_freq = np.array(expected_freq)\n",
    "    \n",
    "    # Normalize expected frequencies to sum to observed frequencies\n",
    "    expected_freq_sum = expected_freq.sum()\n",
    "    observed_freq_sum = observed_freq.sum()\n",
    "    expected_freq = expected_freq * (observed_freq_sum / expected_freq_sum)\n",
    "    \n",
    "    # Ensure no zero expected frequencies\n",
    "    expected_freq = np.where(expected_freq == 0, 1e-10, expected_freq)\n",
    "    \n",
    "    print(\"Observed frequencies:\\n\", observed_freq)\n",
    "    print(\"Expected frequencies:\\n\", expected_freq)\n",
    "    \n",
    "    # Step 5: Perform the chi-square goodness of fit test\n",
    "    chi_square_stat, p_value = chisquare(f_obs=observed_freq, f_exp=expected_freq)\n",
    "    \n",
    "    # Output results\n",
    "    print(f\"Chi-Square Statistic: {chi_square_stat}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis: The data does not follow a negative binomial distribution.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: The data could follow a negative binomial distribution.\")\n",
    "    \n",
    "    return chi_square_stat, p_value, r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: r = 3.619771220237507, p = 0.3161248033764886\n",
      "Observed frequencies:\n",
      " [ 54 101 161 200 250 260 293 253 250 209 155 143 120  91  71  50  56  37\n",
      "  31  30  16  12   9  10   6   3   4   2   2   2   2   1   1   1   1   1]\n",
      "Expected frequencies:\n",
      " [4.47119735e+01 1.10683228e+02 1.74843359e+02 2.23987290e+02\n",
      " 2.53503066e+02 2.64199503e+02 2.59569308e+02 2.43947794e+02\n",
      " 2.21461849e+02 1.95537853e+02 1.68755982e+02 1.42893725e+02\n",
      " 1.19055466e+02 9.78267236e+01 7.94202714e+01 6.37994927e+01\n",
      " 5.07748251e+01 4.00747024e+01 3.13948560e+01 2.44305274e+01\n",
      " 1.88959141e+01 1.45345353e+01 1.11234456e+01 8.47351495e+00\n",
      " 6.42737338e+00 4.85613163e+00 3.65561216e+00 2.74255219e+00\n",
      " 2.05104724e+00 1.52937238e+00 1.13723378e+00 8.43450623e-01\n",
      " 6.24037562e-01 1.33990631e-01 9.79501624e-02 2.04436265e-03]\n",
      "Chi-Square Statistic: 527.9836959516022\n",
      "p-value: 2.5194348890031197e-89\n",
      "Reject the null hypothesis: The data does not follow a negative binomial distribution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(527.9836959516022,\n",
       " 2.5194348890031197e-89,\n",
       " 3.619771220237507,\n",
       " 0.3161248033764886)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_binomial_gof(dfg(1,4)[\"MT-ND1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.12274271988561"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(normiz_2(dfg(1,4))[\"MT-ND1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
